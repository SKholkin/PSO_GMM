{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.mixture import GaussianMixture\n",
    "import numpy as np\n",
    "from utils import Givens2Matrix, QRGivens, eigh_with_fixed_direction_range, find_closest_spd\n",
    "from utils import load_cloud_dataset, load_breast_cancer, load_seg_data, load_digits_dataset, load_satelite_dataset, load_synthetic_dataset\n",
    "from python_example import Givens2Matrix_double as Givens2Matrix\n",
    "from python_example import QRGivens_double as QRGivens\n",
    "from copy import deepcopy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "# from sklearn.exceptions import ConvergenceWarning, ComplexWarning\n",
    "# warnings.filterwarnings(action='ignore', category=ComplexWarning)\n",
    "# warnings.filterwarnings(action='ignore', category=ConvergenceWarning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class EMParticle:\n",
    "    def __init__(self, weights, means, precision_matrices, eigvals_coef, means_coef) -> None:\n",
    "        self.weights = deepcopy(weights)\n",
    "        self.means = deepcopy(means)\n",
    "        self.precision_matrices = deepcopy(precision_matrices)\n",
    "        self.eigvals_coef = eigvals_coef\n",
    "        self.n_comp = self.weights.shape[0]\n",
    "        self.data_dim = self.means.shape[1]\n",
    "        self.means_coef = means_coef\n",
    "\n",
    "    def inject_noise(self):\n",
    "        \n",
    "        eigvals = [np.mean(np.linalg.eigvals(self.precision_matrices[i])) for i in range(self.n_comp)]\n",
    "        \n",
    "        eig_val_max  = [eigvals[i] * self.eigvals_coef for i in range(len(eigvals))]\n",
    "\n",
    "        for i in range(self.n_comp):\n",
    "            \n",
    "            givens_angles = np.random.uniform(-np.pi, np.pi, size=(int(self.data_dim * (self.data_dim - 1) / 2)))\n",
    "            delta_eigvals = np.random.uniform(0, np.mean(eig_val_max), size=self.data_dim)\n",
    "            # print('eig', np.mean(eig_val_max))\n",
    "            \n",
    "            v = Givens2Matrix(np.expand_dims(givens_angles, axis=1))\n",
    "            addition = v @ np.diag(delta_eigvals) @ v.T\n",
    "\n",
    "            self.precision_matrices += addition\n",
    "        # print(np.mean(self.means))\n",
    "        means_delta = np.random.normal(0, self.means_coef * np.mean(self.means), size=(self.n_comp, self.data_dim))\n",
    "        # print(self.means.shape, means_delta.shape)\n",
    "        self.means += means_delta\n",
    "\n",
    "    def run_em_iters(self, iters, data):\n",
    "        gmm = GaussianMixture(n_components=self.weights.shape[0], covariance_type='full',\n",
    "         weights_init=self.weights, means_init=self.means, precisions_init=self.precision_matrices, max_iter=iters)\n",
    "        gmm.fit(data)\n",
    "        self.weights  = gmm.weights_\n",
    "        self.means = gmm.means_\n",
    "        self.precision_matrices = gmm.precisions_\n",
    "        self.curr_score = gmm.score(data)\n",
    "        return gmm.score(data)\n",
    "\n",
    "class NoiseEM:\n",
    "    def __init__(self, n_comp, n_particles, T1, T2, eigval_coef, means_coef) -> None:\n",
    "        self.particles = [None for i in range(n_particles)]\n",
    "        self.n_comp = n_comp\n",
    "        self.T1 = T1\n",
    "        self.T2 = T2\n",
    "        self.eigval_coef = eigval_coef\n",
    "        self.means_coef = means_coef\n",
    "\n",
    "    def run(self, data):\n",
    "        best_score = -np.inf\n",
    "        best_particle = None\n",
    "        for i in range(len(self.particles)):\n",
    "            particle_gmm = GaussianMixture(self.n_comp, covariance_type='full', max_iter=1, n_init=1, init_params='k-means++')\n",
    "            particle_gmm.fit(data)\n",
    "            self.particles[i] = EMParticle(particle_gmm.weights_, particle_gmm.means_, particle_gmm.precisions_, self.eigval_coef, self.means_coef)\n",
    "            \n",
    "        for i in range(self.T1):\n",
    "            for particle in self.particles:\n",
    "                ll = particle.run_em_iters(self.T2, data)\n",
    "                print('LL: ', ll)\n",
    "                if ll > best_score:\n",
    "                    best_score = ll\n",
    "                    best_particle = deepcopy(particle)\n",
    "                # particle.inject_noise()\n",
    "            \n",
    "            for j in range(len(self.particles)):\n",
    "                self.particles[j] = EMParticle(best_particle.weights, best_particle.means, best_particle.precision_matrices, self.eigval_coef, self.means_coef)\n",
    "                self.particles[j].inject_noise()\n",
    "\n",
    "        for particle in self.particles:\n",
    "            ll = particle.run_em_iters(self.T2, data)\n",
    "            if ll > best_score:\n",
    "                best_score = ll\n",
    "            \n",
    "            print('Final LL: ', ll)\n",
    "        print('Best LL: ', best_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LL:  68.76140762766123\n",
      "LL:  69.96093803681335\n",
      "LL:  65.70113094132631\n",
      "LL:  65.99577943526985\n",
      "LL:  68.98821761327493\n",
      "LL:  69.90470355816441\n",
      "LL:  68.87191888298712\n",
      "LL:  70.71383344220318\n",
      "LL:  69.93888553783968\n",
      "LL:  69.83436427776095\n",
      "LL:  67.60871866423422\n",
      "LL:  69.32422934184835\n",
      "LL:  67.62682344094124\n",
      "LL:  67.50021340833462\n",
      "LL:  69.94159302829652\n",
      "LL:  66.57129947053618\n",
      "LL:  63.705404580706826\n",
      "LL:  66.17205537499484\n",
      "LL:  66.79285786770336\n",
      "LL:  68.37075408374385\n",
      "LL:  69.53725555360846\n",
      "LL:  69.9330391107168\n",
      "LL:  69.65519640208119\n",
      "LL:  66.5243678268894\n",
      "LL:  69.4290430834794\n",
      "LL:  67.52111883317822\n",
      "LL:  65.90418773398719\n",
      "LL:  68.29158446036068\n",
      "LL:  67.27426019327044\n",
      "LL:  68.80644876367936\n",
      "LL:  71.16452135108099\n",
      "LL:  70.87735130139015\n",
      "LL:  70.89188193852779\n",
      "LL:  71.22662477663255\n",
      "LL:  71.0628910775597\n",
      "LL:  71.16985448367994\n",
      "LL:  71.21447098659723\n",
      "LL:  71.06289136168778\n",
      "LL:  70.95985266553399\n",
      "LL:  71.21137711386952\n",
      "LL:  71.17112289955782\n",
      "LL:  71.08738583695069\n",
      "LL:  71.18108889595295\n",
      "LL:  70.98647080329619\n",
      "LL:  71.08738698620381\n",
      "LL:  71.06178405877101\n",
      "LL:  71.44455946443837\n",
      "LL:  71.23591070337574\n",
      "LL:  70.49871150719024\n",
      "LL:  71.17533755702827\n",
      "LL:  70.68897630210408\n",
      "LL:  70.96675755797582\n",
      "LL:  70.76196219571766\n",
      "LL:  71.18103844119653\n",
      "LL:  71.18648058366753\n",
      "LL:  71.05251441038828\n",
      "LL:  71.142393949386\n",
      "LL:  71.11032123118652\n",
      "LL:  71.38982634021785\n",
      "LL:  70.68594750377969\n",
      "LL:  70.87135877921476\n",
      "LL:  71.4156996239592\n",
      "LL:  71.2143196921905\n",
      "LL:  71.19473999169438\n",
      "LL:  71.50495337358767\n",
      "LL:  71.04752881212167\n",
      "LL:  71.21431971812476\n",
      "LL:  71.21431965483444\n",
      "LL:  71.37442725646113\n",
      "LL:  71.39939173759701\n",
      "LL:  71.45486421112429\n",
      "LL:  71.21431996561292\n",
      "LL:  71.04707523859135\n",
      "LL:  71.24193792220967\n",
      "LL:  70.99178758312644\n",
      "LL:  71.14821210181223\n",
      "LL:  71.42246271154706\n",
      "LL:  71.38517938611045\n",
      "LL:  71.44565965369003\n",
      "LL:  71.14688998151351\n",
      "LL:  71.27844923470053\n",
      "LL:  71.20896381201739\n",
      "LL:  71.21432008093372\n",
      "LL:  71.33820010300722\n",
      "LL:  71.21431985421644\n",
      "LL:  71.07949704919405\n",
      "LL:  71.15112893113402\n",
      "LL:  71.53932085433806\n",
      "LL:  71.1467012523585\n",
      "LL:  71.44565978735835\n",
      "LL:  70.73291831701208\n",
      "LL:  71.41241927897354\n",
      "LL:  71.3793621068318\n",
      "LL:  71.4497492102221\n",
      "LL:  71.34090089389119\n",
      "LL:  71.472369073651\n",
      "LL:  71.22839407272461\n",
      "LL:  71.2283940433052\n",
      "LL:  71.2283940199816\n",
      "LL:  71.47236910360199\n",
      "LL:  71.17770978546437\n",
      "LL:  71.30922194290719\n",
      "LL:  71.26760444608941\n",
      "LL:  71.3793620564663\n",
      "LL:  70.85024270626872\n",
      "LL:  71.3599062750032\n",
      "LL:  71.4842743924223\n",
      "LL:  71.34090068200264\n",
      "LL:  71.3946525348561\n",
      "LL:  71.34090069352479\n",
      "LL:  71.67857322501551\n",
      "LL:  71.22839402516813\n",
      "LL:  70.82990074668879\n",
      "LL:  71.22839401377236\n",
      "LL:  71.2277967715636\n",
      "LL:  71.34567791744435\n",
      "LL:  71.32558787593419\n",
      "LL:  71.47236916859949\n",
      "LL:  71.3457046154241\n",
      "LL:  71.22839439823049\n",
      "LL:  71.16418337605131\n",
      "LL:  71.67857262264948\n",
      "LL:  71.47236960187567\n",
      "LL:  71.34090076413148\n",
      "LL:  71.22914415724912\n",
      "LL:  71.461254513872\n",
      "LL:  71.2291431751768\n",
      "LL:  71.4547810016288\n",
      "LL:  71.3793621068318\n",
      "LL:  71.43534712627066\n",
      "LL:  71.46119550052104\n",
      "LL:  71.21226680630959\n",
      "LL:  71.45821375362011\n",
      "LL:  71.47236907010164\n",
      "LL:  71.22914338308871\n",
      "LL:  71.32369479659037\n",
      "LL:  70.94323494614743\n",
      "LL:  71.67857241269097\n",
      "LL:  71.6785732525008\n",
      "LL:  71.32160098067988\n",
      "LL:  71.34030149553311\n",
      "LL:  71.21826688634316\n",
      "LL:  71.12932122761909\n",
      "LL:  71.34090069762186\n",
      "LL:  71.47236909486159\n",
      "LL:  71.34090076413148\n",
      "LL:  71.53932084112381\n",
      "LL:  71.34090066628319\n",
      "LL:  71.47236947223965\n",
      "LL:  71.47236882897566\n",
      "LL:  71.34090075883692\n",
      "LL:  71.22914331026803\n",
      "LL:  71.54710473464603\n",
      "LL:  71.22914326966114\n",
      "LL:  71.43065469037985\n",
      "LL:  71.15136240159853\n",
      "LL:  71.22914321825245\n",
      "LL:  71.22839409370978\n",
      "LL:  71.12954900703666\n",
      "LL:  71.34090078006741\n",
      "LL:  70.92334501123699\n",
      "LL:  71.67857192075516\n",
      "LL:  71.340900925548\n",
      "LL:  71.22914320712549\n",
      "LL:  71.51893927719348\n",
      "LL:  71.34090078484688\n",
      "LL:  71.54710473567305\n",
      "LL:  71.57630591129633\n",
      "LL:  71.57301210082896\n",
      "LL:  71.47236907701632\n",
      "LL:  71.67857322578939\n",
      "LL:  71.4723692652972\n",
      "LL:  71.34571389234331\n",
      "LL:  71.4723690653665\n",
      "LL:  71.53932110024691\n",
      "LL:  71.3293325957161\n",
      "LL:  71.47236907125979\n",
      "LL:  71.5375339967151\n",
      "LL:  71.54710474909184\n",
      "LL:  71.36668048351294\n",
      "LL:  71.34090093505083\n",
      "LL:  71.66441729854289\n",
      "LL:  71.4723693043692\n",
      "LL:  71.22593794312198\n",
      "LL:  71.35468573928881\n",
      "LL:  71.51083034731678\n",
      "LL:  71.34090068091747\n",
      "LL:  71.47236934756216\n",
      "LL:  71.46993842902295\n",
      "LL:  71.67857320862328\n",
      "LL:  70.922434900096\n",
      "LL:  71.47236891414529\n",
      "LL:  70.92334538741773\n",
      "LL:  71.34090094101101\n",
      "LL:  71.45471800732068\n",
      "LL:  71.60095771607185\n",
      "LL:  71.69032491571679\n",
      "LL:  71.54651217895297\n",
      "LL:  71.67857325065981\n",
      "LL:  71.57289330101935\n",
      "LL:  71.21891179275974\n",
      "LL:  71.59090886445978\n",
      "LL:  71.37526563432827\n",
      "LL:  71.34600949179674\n",
      "LL:  71.23065943941663\n",
      "LL:  71.37936198005703\n",
      "LL:  71.20725871631457\n",
      "LL:  71.48545746284915\n",
      "LL:  71.47236931807188\n",
      "LL:  71.21828933925899\n",
      "LL:  70.82990070600442\n",
      "LL:  71.20721432353375\n",
      "LL:  70.46913296327266\n",
      "LL:  71.43534718392571\n",
      "LL:  71.09591802782518\n",
      "LL:  70.82990100421699\n",
      "LL:  71.40515030457048\n",
      "LL:  71.4582134898266\n",
      "LL:  71.22914309059334\n",
      "LL:  71.40126435276437\n",
      "LL:  71.4582134381842\n",
      "LL:  71.22914327685632\n",
      "LL:  71.64326531878588\n",
      "LL:  71.105801629298\n",
      "LL:  71.45821342701119\n",
      "LL:  71.39536828150527\n",
      "LL:  71.2291432487368\n",
      "LL:  71.26760433336763\n",
      "LL:  70.87483388052956\n",
      "LL:  71.2291432491521\n",
      "LL:  71.3457053305201\n",
      "LL:  71.22914303045842\n",
      "LL:  71.37526567980818\n",
      "LL:  71.35773170316777\n",
      "LL:  71.31783775442601\n",
      "LL:  71.25370022031377\n",
      "LL:  71.57289322492278\n",
      "LL:  70.8299005539764\n",
      "LL:  71.29303413559771\n",
      "LL:  71.26760445830124\n",
      "LL:  70.82990104221193\n",
      "LL:  71.22914328198921\n",
      "LL:  71.34571239150185\n",
      "LL:  71.36668970466006\n",
      "LL:  70.97090695743324\n",
      "LL:  71.13885497993856\n",
      "LL:  70.69192549619562\n",
      "LL:  71.24193779861822\n",
      "LL:  70.82990060588527\n",
      "LL:  71.36631963447758\n",
      "LL:  71.4012600006497\n",
      "LL:  71.2260910245716\n",
      "LL:  71.26760441335772\n",
      "LL:  71.22914311414145\n",
      "LL:  71.57289385807155\n",
      "LL:  71.36668967187629\n",
      "LL:  71.26377935077417\n",
      "LL:  71.21322062975734\n",
      "LL:  71.4267937685402\n",
      "LL:  71.22609588578692\n",
      "LL:  71.40515104954721\n",
      "LL:  71.40513943271009\n",
      "LL:  71.22609611446839\n",
      "LL:  71.21926289901637\n",
      "LL:  71.22610021092616\n",
      "LL:  70.82989965259276\n",
      "LL:  71.36668883331552\n",
      "LL:  71.22914303045842\n",
      "LL:  71.26760445830124\n",
      "LL:  71.22914300128485\n",
      "LL:  71.1018663354712\n",
      "LL:  71.22914323009994\n",
      "LL:  71.45821347844992\n",
      "LL:  71.36948956064944\n",
      "LL:  71.4338378859143\n",
      "LL:  71.4051510881772\n",
      "LL:  71.26760434186916\n",
      "LL:  71.22914322623515\n",
      "LL:  71.2921216669666\n",
      "LL:  70.82990053942945\n",
      "LL:  70.9821943544485\n",
      "LL:  71.26760432684975\n",
      "LL:  71.35468427188745\n",
      "LL:  71.43229371945212\n",
      "LL:  71.45821365578968\n",
      "LL:  71.45821341324273\n",
      "LL:  71.45821359925789\n",
      "LL:  71.2676043405218\n",
      "LL:  71.2114922465768\n",
      "LL:  71.34571579930268\n",
      "LL:  71.45821351983099\n",
      "LL:  71.37526563505978\n",
      "LL:  70.74784923974617\n",
      "LL:  71.5278047872306\n",
      "LL:  71.40515060649557\n",
      "LL:  71.45821350773812\n",
      "LL:  71.45821344177998\n",
      "LL:  70.86836196488754\n",
      "LL:  71.26760441877686\n",
      "LL:  71.26760441877686\n",
      "Final LL:  71.2260957869417\n",
      "Final LL:  70.8299006720604\n",
      "Final LL:  71.40515107869919\n",
      "Final LL:  71.45821342478366\n",
      "Final LL:  71.12541705591585\n",
      "Final LL:  70.82990071317715\n",
      "Final LL:  70.9822474701061\n",
      "Final LL:  71.2291431890353\n",
      "Final LL:  71.45821354617148\n",
      "Final LL:  71.22914326305079\n",
      "Final LL:  71.22914320629259\n",
      "Final LL:  71.57289382352948\n",
      "Final LL:  71.47079709424297\n",
      "Final LL:  71.45821347355505\n",
      "Final LL:  71.34090092331695\n",
      "Final LL:  71.17703206260202\n",
      "Final LL:  71.22914301107384\n",
      "Final LL:  71.2291430986708\n",
      "Final LL:  71.2676044983014\n",
      "Final LL:  71.45821351354914\n",
      "Final LL:  71.45821343672677\n",
      "Final LL:  71.22914321950786\n",
      "Final LL:  71.35773165168\n",
      "Final LL:  71.45821346594957\n",
      "Final LL:  71.22609544724075\n",
      "Final LL:  70.74785146848824\n",
      "Final LL:  71.22914348835306\n",
      "Final LL:  71.39543111476758\n",
      "Final LL:  71.22914317212557\n",
      "Final LL:  71.25358151255062\n",
      "Best LL:  71.69032491571679\n"
     ]
    }
   ],
   "source": [
    "from utils import load_dataset\n",
    "data = load_seg_data()\n",
    "data = load_dataset('seg')\n",
    "T1 = 10\n",
    "T2 = 10\n",
    "n_comp = 10\n",
    "n_particles = 30\n",
    "\n",
    "eigvals_coef = 0.1\n",
    "means_coef = 0.1\n",
    "\n",
    "em = NoiseEM(n_comp, n_particles, T1, T2, eigvals_coef, means_coef)\n",
    "\n",
    "with warnings.catch_warnings():\n",
    "    warnings.simplefilter(\"ignore\")\n",
    "    em.run(data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "71.43196036534148"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "ref_gmm = GaussianMixture(n_comp, n_init=int(n_particles * T1 / 3), max_iter=T2 * 3, verbose=0, verbose_interval=1)\n",
    "ref_gmm.fit(data)\n",
    "ref_gmm.score(data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "vscode": {
   "interpreter": {
    "hash": "50e08e26be32a7b8922986e395fa6399600d4448a35a035137afed8a79926531"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
